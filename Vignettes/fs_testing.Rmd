---
title: "forestsearch examples"
output: 
  html_document:
         code_folding: hide
---


```{r}

library(weightedsurv)

# library(forestsearch) 

library(survival)
df_gbsg <- gbsg
df_gbsg$tte <- df_gbsg$rfstime / 30.4375
df_gbsg$event <- df_gbsg$status
df_gbsg$treat <- df_gbsg$hormon
df_gbsg$grade3 <- ifelse(df_gbsg$grade == "3", 1, 0)
# create id name
df_gbsg$id <- seq_len(nrow(df_gbsg))
# If missing, then created automatically

tte.name <- "tte"
event.name <- "event"
treat.name <- "treat"
id.name <- "id"
arms <- c("treat", "control")

```

## Subgroup identification analysis

```{r, fig.width = 8, fig.height = 6}

# Baseline factors from which candidate subgroups are formed
confounders.name<-c("age","meno","size","grade3","nodes","pgr","er")

library(doFuture)
library(doRNG)
registerDoFuture()
registerDoRNG()

# conf_force 'forces' a specific covariate cut, eg. 'age <= 65'


system.time({fs <- forestsearch(df_gbsg,  confounders.name=confounders.name,
                   outcome.name = "tte", treat.name = "treat", event.name = "event", id.name = "id",
                   hr.threshold = 1.25, hr.consistency = 1.0, pconsistency.threshold = 0.90,
                   sg_focus = "hrMaxSG",
                   showten_subgroups = FALSE, details=TRUE,
                   conf_force = c("age <= 65", "er <= 0", "er <= 1", "er <= 2"," er <= 5"),
                   cut_type = "default", use_grf = TRUE, plot.grf = TRUE, use_lasso = TRUE,
                   maxk = 2, n.min = 60, d0.min = 10, d1.min = 10,
                   plot.sg = TRUE, by.risk = 12,
                   parallel_args = list(plan="sequential", workers = 12, show_message = TRUE)
                   )
})

# reset workeres
plan("sequential")

```

## Show (up to) top 10 subgroups

```{r}
res_tabs <- sg_tables(fs, ndecimals = 3)
res_tabs$sg10_out
```

## Un-adjusted summary estimates

```{r}
res_tabs$tab_estimates
```


## Bootstrap bias-correction and 95% CI estimation

```{r, eval = FALSE}
# Just run a few for illustration 
# In practice, recommend minimum of NB = 300 to 400 re-samples
# NOTE: workers = 1 and reset_parallel_fs = FALSE will use parallel process per the above forestsearch (fs) data analysis call 
# where workers are set to 12 which is the maximum on my machine;
# Also, note that if workers is set to a higher value than the max cores, this will be re-set to the maximum (max cores)


#options(warn = -1)
# Needed for a combined bootstrap plot (otherwise if not avaialable will not produce)
library(patchwork)

options(warn = -1)

output_dir <- "results/"
save_results <- dir.exists(output_dir)

NB <- 10

t.start <- proc.time()[3]

fs_bc <- forestsearch_bootstrap_dofuture(fs.est = fs, nb_boots = NB, show_three = FALSE, details = TRUE, create_summary = TRUE, create_plots = TRUE)

plan("sequential")

t.now<-proc.time()[3]
t.min<-(t.now-t.start)/60
cat("Minutes (total) for bootstrap (boots,mins)",c(NB,t.min),"\n")
cat("Projected minutes for 1000",c(t.min*(1000/NB)),"\n")


if (save_results) {
    filename <- file.path(output_dir, 
                         paste0("gbsg_results_B=", 
                                format(NB), 
                                ".RData"))
    save(fs_bc, fs, file = filename)
    cat("\nResults saved to:", filename, "\n")
}

# check_boot <- subset(fs_bc$results, is.na(H_biasadj_1))
# check4 <- subset(check_boot, boot_id == 4)
# args_forestsearch_call <- fs$args_call_all
# parallel_args <- resolve_bootstrap_parallel_args(parallel_args, args_forestsearch_call)
# cox.formula.boot <- do.call(build_cox_formula,filter_call_args(args_forestsearch_call, build_cox_formula))
# getbadboot <- bootstrap_reproduce_aboot(this_boot = 15, fs.est = fs, cox.formula.boot = cox.formula.boot) 


```

```{r}
#load("~/Library/CloudStorage/OneDrive-MerckSharp&DohmeLLC/documents/GitHub/forestsearch/Vignettes/results/gbsg_results_B=1000.RData")
sg_tab <- fs_bc$summary$table
sg_tab

event_summary <- summarize_bootstrap_events(fs_bc, threshold = 10)

```

```{r, fig.width = 10, fig.height = 8}

fs_bc$summary$plots$combined

```


## Decision Function
```{r decision-function}
#' Decide sg_focus Based on Study Goal
#'
#' @param study_goal Character string indicating the primary study goal
#' @return Recommended sg_focus setting
#' @examples
#' decide_sg_focus("regulatory_safety")
#' decide_sg_focus("population_health")

decide_sg_focus <- function(study_goal) {
  
  decision_map <- list(
    "regulatory_safety" = "hr",        # Most reliable evidence
    "population_health" = "maxSG",     # Protect most patients
    "precision_medicine" = "minSG",    # Most targeted restriction
    "benefit_risk_balance" = "hrMaxSG", # Large group with meaningful harm
    "biomarker_development" = "hrMinSG" # Specific high-risk signature
  )
  
  if (!study_goal %in% names(decision_map)) {
    stop("Unknown study goal. Choose from: ", 
         paste(names(decision_map), collapse = ", "))
  }
  
  sg_focus <- decision_map[[study_goal]]
  
  cat("Study Goal:", study_goal, "\n")
  cat("Recommended sg_focus:", sg_focus, "\n")
  
  return(sg_focus)
}

# Example usage
decide_sg_focus("regulatory_safety")
```

# Impact on Algorithm Behavior

## Internal Sorting Logic
```{r sorting-logic, eval=FALSE}
# From subgroup_consistency.R
sort_subgroups <- function(result_new, sg_focus) {
  if (sg_focus == "hr") 
    data.table::setorder(result_new, -Pcons, -hr, K)  # Reliability first
  
  if (sg_focus %in% c("hrMaxSG", "maxSG")) 
    data.table::setorder(result_new, -N, -Pcons, K)   # Size first
  
  if (sg_focus %in% c("hrMinSG", "minSG")) 
    data.table::setorder(result_new, N, -Pcons, K)    # Specificity first
  
  result_new
}
```

## Parameter Interactions
```{r parameter-interactions, echo=FALSE}
param_interact <- data.frame(
  sg_focus = c("hr", "maxSG", "minSG", "hrMaxSG", "hrMinSG"),
  Typical_hr_threshold = c("1.25 (moderate)", "1.10 (low)", "1.50 (high)", 
                           "1.30 (moderate)", "1.50 (high)"),
  Typical_pconsistency = c("0.90 (high)", "0.85 (moderate)", "0.85 (moderate)",
                           "0.90 (high)", "0.90 (high)"),
  stop_threshold = c("0.90", "Variable*", "Variable*", "1.00", "1.00"),
  stringsAsFactors = FALSE
)

kable(param_interact,
      caption = "Typical Parameter Settings by sg_focus",
      col.names = c("sg_focus", "Typical hr.threshold", 
                    "Typical pconsistency.threshold", "stop.threshold"))
```

*Variable stop.threshold for size-based focus requires special handling based on the specific analysis goals.

# Practical Examples by Study Type

## Phase II Safety Study
```{r phase2-example, eval=FALSE}
# Option 1: Find most reliable signal
result_reliable <- forestsearch(
  df.analysis = phase2_data,
  sg_focus = "hr",              # Most reliable signal
  hr.threshold = 1.25,
  pconsistency.threshold = 0.85,
  n.min = 30,                   # Smaller sample OK for phase II
  d0.min = 5,
  d1.min = 5
)

# Option 2: Find highest-risk profile
result_highrisk <- forestsearch(
  df.analysis = phase2_data,
  sg_focus = "minSG",           # Most specific risk
  hr.threshold = 1.5,           # Higher threshold
  pconsistency.threshold = 0.80,
  n.min = 20,                   # Very specific groups OK
  d0.min = 5,
  d1.min = 5
)
```

## Phase III Confirmatory Trial
```{r phase3-example, eval=FALSE}
# Option 1: Regulatory standard
result_regulatory <- forestsearch(
  df.analysis = phase3_data,
  sg_focus = "hr",              # Regulatory standard
  hr.threshold = 1.3,
  pconsistency.threshold = 0.95, # Very high confidence
  n.min = 100,                  # Large samples required
  d0.min = 20,
  d1.min = 20
)

# Option 2: If population impact matters
result_population <- forestsearch(
  df.analysis = phase3_data,
  sg_focus = "hrMaxSG",         # Balance effect and size
  hr.threshold = 1.3,
  hr.consistency = 1.15,        # Must maintain effect
  pconsistency.threshold = 0.90,
  n.min = 80
)
```

## Post-Market Surveillance
```{r postmarket-example, eval=FALSE}
# Population protection priority
result_surveillance <- forestsearch(
  df.analysis = realworld_data,
  sg_focus = "maxSG",           # Protect most patients
  hr.threshold = 1.15,          # Lower threshold for safety
  pconsistency.threshold = 0.85,
  n.min = 100,
  d0.min = 15,
  d1.min = 15
)
```

## Biomarker Development
```{r biomarker-example, eval=FALSE}
# Specific signature with large effect
result_biomarker <- forestsearch(
  df.analysis = biomarker_trial,
  sg_focus = "hrMinSG",         # Specific + harmful
  hr.threshold = 2.0,           # Large effect required
  hr.consistency = 1.5,         # Must maintain large effect
  pconsistency.threshold = 0.90,
  n.min = 30,                   # Small specific groups OK
  d0.min = 10,
  d1.min = 10
)
```

# Accessing Results

## Understanding Output Structure
```{r output-structure, eval=FALSE}
# The grp.consistency object contains results for all approaches
fs_result <- forestsearch(df.analysis = trial_data, sg_focus = "hr")

# Access different sorting results
hr_results <- fs_result$grp.consistency$out_hr      # Sorted by HR priority
maxSG_results <- fs_result$grp.consistency$out_maxSG # Sorted by size (large)
minSG_results <- fs_result$grp.consistency$out_minSG # Sorted by size (small)

# The final selection depends on sg_focus
final_subgroup <- fs_result$sg.harm  # This is determined by sg_focus

# View top 10 candidates by different criteria
if (!is.null(hr_results)) {
  print(hr_results$result[1:min(10, nrow(hr_results$result)), ])
}
```

## Comparing Different sg_focus Results
```{r compare-results, eval=FALSE}
# Run same analysis with different sg_focus settings
compare_sg_focus <- function(df, ...) {
  
  focus_options <- c("hr", "maxSG", "minSG", "hrMaxSG", "hrMinSG")
  results <- list()
  
  for (focus in focus_options) {
    cat("\nRunning with sg_focus =", focus, "\n")
    
    res <- forestsearch(
      df.analysis = df,
      sg_focus = focus,
      details = FALSE,
      ...
    )
    
    if (!is.null(res$sg.harm)) {
      results[[focus]] <- list(
        subgroup = res$sg.harm,
        size = sum(res$df.est$treat.recommend == 0),
        consistency = res$grp.consistency$out_hr$result$Pcons[1]
      )
    } else {
      results[[focus]] <- "No subgroup found"
    }
  }
  
  return(results)
}

# Example usage
comparison <- compare_sg_focus(
  df = trial_data,
  hr.threshold = 1.25,
  pconsistency.threshold = 0.85,
  n.min = 50
)
```

# Statistical Considerations

## Power Trade-offs
```{r power-tradeoffs, echo=FALSE}
power_comparison <- data.frame(
  sg_focus = c("maxSG", "minSG", "hr"),
  Statistical_Power = c("Higher (more patients)", 
                        "Lower (fewer patients)", 
                        "Balanced"),
  Effect_Size = c("Potentially diluted", 
                  "Potentially stronger", 
                  "Based on consistency"),
  Clinical_Impact = c("Broad restrictions", 
                      "Targeted restrictions", 
                      "Evidence-based restrictions"),
  stringsAsFactors = FALSE
)

kable(power_comparison,
      caption = "Power and Impact Trade-offs by sg_focus")
```

## Implicit Utility Functions
```{r utility-functions}
# Utility function implicit in each focus

utility_hr <- function(subgroup) {
  # Maximize: consistency * effect_size
  subgroup$Pcons * subgroup$hr
}

utility_maxSG <- function(subgroup) {
  # Maximize: affected_population * (effect > threshold)
  subgroup$N * (subgroup$hr > hr.threshold)
}

utility_minSG <- function(subgroup) {
  # Maximize: specificity * effect_size
  (1/subgroup$N) * subgroup$hr
}

utility_hrMaxSG <- function(subgroup, hr.threshold) {
  # Maximize: size | hr > threshold
  ifelse(subgroup$hr > hr.threshold, subgroup$N, 0)
}

utility_hrMinSG <- function(subgroup, hr.threshold) {
  # Maximize: specificity | hr > threshold  
  ifelse(subgroup$hr > hr.threshold, 1/subgroup$N * subgroup$hr, 0)
}
```

# Sensitivity Analysis

## Testing Multiple sg_focus Settings
```{r sensitivity-analysis, eval=FALSE}
# Sensitivity analysis across sg_focus options
run_sg_sensitivity <- function(df, base_params) {
  
  focus_grid <- c("hr", "maxSG", "minSG", "hrMaxSG", "hrMinSG")
  
  results <- data.frame(
    sg_focus = character(),
    subgroup_found = logical(),
    subgroup_size = integer(),
    subgroup_hr = numeric(),
    consistency = numeric(),
    n_factors = integer(),
    stringsAsFactors = FALSE
  )
  
  for (focus in focus_grid) {
    res <- do.call(forestsearch, c(
      list(df.analysis = df, sg_focus = focus),
      base_params
    ))
    
    if (!is.null(res$sg.harm)) {
      results <- rbind(results, data.frame(
        sg_focus = focus,
        subgroup_found = TRUE,
        subgroup_size = sum(res$df.est$treat.recommend == 0),
        subgroup_hr = res$grp.consistency$out_hr$result$hr[1],
        consistency = res$grp.consistency$out_hr$result$Pcons[1],
        n_factors = length(res$sg.harm),
        stringsAsFactors = FALSE
      ))
    } else {
      results <- rbind(results, data.frame(
        sg_focus = focus,
        subgroup_found = FALSE,
        subgroup_size = NA,
        subgroup_hr = NA,
        consistency = NA,
        n_factors = NA,
        stringsAsFactors = FALSE
      ))
    }
  }
  
  return(results)
}

# Example usage
base_params <- list(
  hr.threshold = 1.25,
  pconsistency.threshold = 0.85,
  n.min = 50,
  d0.min = 10,
  d1.min = 10
)

sensitivity_results <- run_sg_sensitivity(trial_data, base_params)
print(sensitivity_results)
```

# Key Insights and Recommendations

## Philosophy of Each Approach
```{r philosophy-table, echo=FALSE}
philosophy <- data.frame(
  sg_focus = c("hr", "maxSG", "minSG", "hrMaxSG", "hrMinSG"),
  Core_Question = c(
    "What harm are we most sure about?",
    "How many patients could we protect?",
    "Who is at highest risk?",
    "What's the biggest problem we're confident about?",
    "What's the most specific serious risk?"
  ),
  Statistical_Philosophy = c(
    "Maximize reliability",
    "Maximize coverage",
    "Maximize specificity",
    "Balance impact and confidence",
    "Precision with significance"
  ),
  Clinical_Philosophy = c(
    "Evidence-based medicine",
    "Population health",
    "Precision medicine",
    "Risk-benefit optimization",
    "Targeted intervention"
  ),
  stringsAsFactors = FALSE
)

DT::datatable(philosophy,
              caption = "Philosophy Behind Each sg_focus Option",
              options = list(pageLength = 5, dom = 't'))
```

## Summary Recommendations

1. **Start with `sg_focus = "hr"`** for initial exploration - most balanced approach
2. **Consider your stakeholders**: 
  - Regulators → "hr"
- Health systems → "maxSG"
- Precision medicine → "minSG" or "hrMinSG"
3. **Run sensitivity analyses** with multiple sg_focus settings
4. **Document your choice** and rationale in study protocols
5. **Report results from multiple perspectives** even if one is primary

## Final Notes

- All sg_focus options evaluate the **same candidate subgroups**
  - The parameter only affects **which one is selected as primary**
  - No additional multiple testing burden between options
- Consider pre-specifying sg_focus in your statistical analysis plan

---
  
  *This document provides comprehensive guidance on the sg_focus parameter in ForestSearch. Each option represents a valid statistical and clinical perspective on subgroup identification for treatment harm.*

# Required R Packages for ForestSearch Analysis

1. **grf**
   - Generalized Random Forests for causal inference and subgroup identification.

2. **policytree**
   - Policy learning and tree-based subgroup identification.

3. **data.table**
   - Fast and memory-efficient data manipulation.

4. **randomForest**
   - Random forest algorithms for variable selection and prediction.

5. **survival**
   - Survival analysis, including Cox proportional hazards models.

6. **weightedSurv**
   - Weighted survival curves and related methods.

7. **future.apply**
   - Parallelization of apply functions using the future framework.

8. **foreach**
   - Looping construct for parallel execution.

9. **doFuture**
   - Backend for foreach to enable parallelization with future.

10. **doRNG**
    - Reproducible parallel foreach loops.

11. **DiagrammeR**
    - Visualization of diagrams and flowcharts (used for schematic diagrams).

## Usage Notes
- All packages should be installed before running the analysis.
- Some packages (e.g., `DiagrammeR`) are only needed for visualization and not for the core analysis.
- The function `ensure_packages()` in your code can be used to check and install missing packages automatically.


# Installing Required R Packages for ForestSearch Analysis

To run ForestSearch and its associated bootstrap/validation workflow, you need to install the following R packages:

- grf
- policytree
- data.table
- randomForest
- survival
- weightedSurv
- future.apply
- foreach
- doFuture
- doRNG
- DiagrammeR

You can install all these packages from CRAN using the following R code:

```r
# List of required packages
required_packages <- c(
  'grf', 'policytree', 'data.table', 'randomForest', 'survival',
  'future.apply', 'foreach', 'doFuture', 'doRNG', 'DiagrammeR'
)

# Install any packages that are not already installed
new_packages <- required_packages[!(required_packages %in% installed.packages()[,'Package'])]
if(length(new_packages)) install.packages(new_packages)

# Load all packages
lapply(required_packages, library, character.only = TRUE)

# For weightedSurv, at the time of this note, is only available on github

library(devtools)
install_github("larry-leon/weightedSurv")


```

**Notes:**
- You only need to run the installation code once per R environment.
- If you encounter any errors, make sure your R version is up to date and you have internet access.
- Some packages (e.g., `DiagrammeR`) are only needed for visualization and not for the core analysis.




# Summary of forestsearch_bootstrap_dofuture.R

This file provides functions for bootstrapping analysis in ForestSearch, with parallelization using doFuture.

## Key Functions

### ensure_packages
Installs and loads required packages if not already available.
- **Arguments:** pkgs (character vector of package names)
- **Returns:** None (loads packages)

### build_cox_formula
Constructs a Cox model formula from variable names.
- **Arguments:** outcome.name, event.name, treat.name (character)
- **Returns:** R formula object for Cox regression

### fit_cox_models
Fits Cox models for two subgroups defined by treatment recommendation.
- **Arguments:** df (data frame), formula (Cox model formula)
- **Returns:** List with HR and SE for each subgroup

### bootstrap_ystar
Generates a bootstrap matrix for Ystar using parallel processing.
- **Arguments:** df (data frame), nb_boots (integer)
- **Returns:** Matrix of bootstrap samples

### bootstrap_results
Runs bootstrap analysis for ForestSearch, fitting Cox models and bias correction.
- **Arguments:** fs.est (ForestSearch results), df_boot_analysis (data frame), cox.formula.boot (formula), nb_boots (integer), show_three (logical), H_obs, Hc_obs (numeric), reset_parallel (logical), boot_workers (integer)
- **Returns:** Data.table with bias-adjusted estimates and search metrics

### format_CI
Formats confidence interval for estimates.
- **Arguments:** estimates (data frame/data.table), col_names (character vector)
- **Returns:** Character string formatted as 'estimate (lower, upper)'

### forestsearch_bootstrap_dofuture
Orchestrates bootstrap analysis for ForestSearch using doFuture parallelization.
- **Arguments:** fs.est (ForestSearch results), nb_boots (integer), details (logical), show_three (logical), reset_parallel_fs (logical), boot_workers (integer), parallel_args (list)
- **Returns:** List with bootstrap results, confidence intervals, summary table, Ystar matrix, and estimates

## Usage Notes
- Ensure all required packages are installed before running bootstrap analysis.
- The main function for analysis is `forestsearch_bootstrap_dofuture`, which returns a comprehensive list of results for downstream analysis and reporting.
- Parallelization is handled via doFuture and foreach for efficient computation.



```{r flowchartB, fig.cap="Figure 1: Overview of forestsearch steps", label="fig:flowB", echo = FALSE, eval = FALSE}
# More detailed flowchart with example values
flow2 <- grViz("
digraph detailed_validation {
  # Graph settings
  graph [layout = dot, rankdir = TB, fontsize = 14, 
         label = 'ForestSearch Subgroup Validation Pipeline', 
         labelloc = t]
  
  # Node settings  
  node [shape = box, style = 'filled,rounded', fillcolor = white, 
        fontname = Arial, fontsize = 11, penwidth = 2]
  
  # Stage 1: Discovery
  subgraph cluster_0 {
    label = 'Stage 1: Discovery'
    style = 'dashed,rounded'
    color = darkgreen
    fontsize = 12
    
    input [label = 'Subgroup Found\\nHR = 1.45\\nn = 120 patients\\nevents = 35', 
           fillcolor = '#E8F5E9', color = darkgreen]
    test1 [label = '1.45 > 1.25?\\n(hr.threshold)', 
           shape = diamond, fillcolor = '#FFF3E0', color = orange]
    pass1 [label = 'Proceed to\\nValidation', fillcolor = '#E8F5E9', color = darkgreen]
  }
  
  # Stage 2: Validation
  subgraph cluster_1 {
    label = 'Stage 2: Split-Sample Validation'
    style = 'dashed,rounded'
    color = darkblue
    fontsize = 12
    
    split [label = 'Random Split #i\\n(i = 1 to 1000)\\n60 patients each half', 
           fillcolor = '#E3F2FD', color = darkblue]
    calc [label = 'Calculate:\\nHR₁ = 1.38\\nHR₂ = 1.42', 
          fillcolor = '#E3F2FD', color = darkblue]
    test2 [label = '1.38 > 1.0?\\n1.42 > 1.0?\\n(hr.consistency)', 
           shape = diamond, fillcolor = '#FFF3E0', color = orange]
    success [label = 'Split i: ✓\\nConsistent', fillcolor = '#E8F5E9', color = darkgreen]
    fail [label = 'Split i: ✗\\nInconsistent', fillcolor = '#FFEBEE', color = darkred]
  }
  
  # Stage 3: Confirmation
  subgraph cluster_2 {
    label = 'Stage 3: Final Selection'
    style = 'dashed,rounded'
    color = purple
    fontsize = 12
    
    tally [label = 'Final Tally:\\n920/1000 consistent\\n(92% success rate)', 
           fillcolor = '#F3E5F5', color = purple]
    test3 [label = '0.92 ≥ 0.90?\\n(pconsistency.threshold)', 
           shape = diamond, fillcolor = '#FFF3E0', color = orange]
    selected [label = 'SELECTED\\nStable Subgroup\\nReport: HR=1.45', 
              fillcolor = '#C8E6C9', color = darkgreen, penwidth = 3]
    rejected [label = 'REJECTED\\nUnstable Effect', 
              fillcolor = '#FFCDD2', color = darkred]
  }
  
  # Edges
  input -> test1
  test1 -> pass1 [label = 'Yes', color = darkgreen]
  test1 -> rejected [label = 'No', color = darkred]
  pass1 -> split
  split -> calc
  calc -> test2
  test2 -> success [label = 'Both Yes', color = darkgreen]
  test2 -> fail [label = 'Any No', color = darkred]
  success -> tally
  fail -> tally
  tally -> test3
  test3 -> selected [label = 'Yes', color = darkgreen, penwidth = 2]
  test3 -> rejected [label = 'No', color = darkred]
  
  # # Add legend
  # subgraph cluster_legend {
  #   label = 'Parameter Effects'
  #   style = filled
  #   fillcolor = '#FAFAFA'
  #   fontsize = 10
  #   
  #   legend1 [shape = none, fillcolor = none,
  #            label = 'hr.threshold: Higher = Fewer candidates']
  #   legend2 [shape = none, fillcolor = none,
  #            label = 'hr.consistency: Higher = Stricter validation']  
  #   legend3 [shape = none, fillcolor = none,
  #            label = 'pconsistency.threshold: Higher = More confidence']
  # }
}
", width =800, height = 400)

flow2

```


# Overview of Main functions


```{r flowchart2, fig.cap="Figure 2: Main functions", label="fig:flow2", echo = FALSE, fig.width = 10, fig.height = 10}
library(DiagrammeR)
main_flow <- grViz("
digraph main_flow {
  graph [rankdir = LR]
  node [shape=box, style=filled, fillcolor=\"#e6f2ff\", fontname=\"Arial\"]
  edge [fontname=\"Arial\"]
  forestsearch [label=\"forestsearch (main entry)\", fillcolor=\"#b3d1ff\"]
  get_FSdata [label=\"get_FSdata\"]
  grf_subg [label=\"grf.subg.harm.survival\"]
  subgroup_search [label=\"subgroup.search\"]
  subgroup_consistency [label=\"subgroup.consistency\"]
  get_dfpred [label=\"get_dfpred\"]
  SG_tab_estimates [label=\"SG_tab_estimates\"]
  forestsearch_bootstrap [label=\"forestsearch_bootstrap_dofuture\"]
  forestsearch -> get_FSdata
  forestsearch -> grf_subg
  forestsearch -> subgroup_search
  forestsearch -> subgroup_consistency
  forestsearch -> get_dfpred
  forestsearch -> SG_tab_estimates
  forestsearch -> forestsearch_bootstrap
}
", width = 600, height = 400)
main_flow
```


# Overview of Helper Functions


```{r flowchart3, fig.cap="Figure 3: Helpers functions", label="fig:flow3", echo = FALSE, fig.width = 10, fig.height = 10}
library(DiagrammeR)
helpers_flow <- grViz("
digraph helpers_flow {
  graph [rankdir = LR]
  node [shape=box, style=filled, fillcolor=\"#e6f2ff\", fontname=\"Arial\"]
  edge [fontname=\"Arial\"]
  # get_FSdata helpers
  get_FSdata [label=\"get_FSdata\"]
  get_FSdata -> lasso_selection
  get_FSdata -> get_conf_force
  get_FSdata -> filter_by_lassokeep
  get_FSdata -> is_continuous
  get_FSdata -> cut_var
  get_FSdata -> process_conf_force_expr
  get_FSdata -> dummy
  get_FSdata -> dummy2
  # grf_subg helpers
  grf_subg [label=\"grf.subg.harm.survival\"]
  grf_subg -> policy_tree
  grf_subg -> causal_survival_forest
  grf_subg -> double_robust_scores
  grf_subg -> aggregate
  # subgroup_search helpers
  subgroup_search [label=\"subgroup.search\"]
  subgroup_search -> get_combinations_info
  subgroup_search -> get_subgroup_membership
  subgroup_search -> get_covs_in
  subgroup_search -> extract_idx_flagredundancy
  # subgroup_consistency helpers
  subgroup_consistency [label=\"subgroup.consistency\"]
  subgroup_consistency -> sort_subgroups
  subgroup_consistency -> extract_subgroup
  subgroup_consistency -> sg_consistency_out
  subgroup_consistency -> remove_redundant_subgroups
  subgroup_consistency -> get_split_hr
  subgroup_consistency -> setup_parallel_SGcons
  # forestsearch_bootstrap helpers
  forestsearch_bootstrap [label=\"forestsearch_bootstrap_dofuture\"]
  forestsearch_bootstrap -> bootstrap_results
  forestsearch_bootstrap -> bootstrap_ystar
  forestsearch_bootstrap -> get_dfRes
  forestsearch_bootstrap -> get_Cox_sg
  forestsearch_bootstrap -> ci_est
  forestsearch_bootstrap -> get_targetEst
  forestsearch_bootstrap -> fit_cox_models
  forestsearch_bootstrap -> build_cox_formula
  forestsearch_bootstrap -> ensure_packages
  forestsearch_bootstrap -> setup_parallel_SGcons
  # SG_tab_estimates helpers
  SG_tab_estimates [label=\"SG_tab_estimates\"]
  SG_tab_estimates -> analyze_subgroup
  analyze_subgroup [label=\"analyze_subgroup\"]
  analyze_subgroup -> cox_summary
  analyze_subgroup -> km_summary
  analyze_subgroup -> rmst_calculation
  analyze_subgroup -> calculate_counts
  analyze_subgroup -> calculate_potential_hr
  SG_tab_estimates -> prepare_subgroup_data
  SG_tab_estimates -> format_results
  SG_tab_estimates -> format_CI
}
", width = 800, height = 800)
helpers_flow
```

# Overview of all functions

```{r flowchart4, fig.cap="Figure 4: Overview of ALL functions", label="fig:flow4", echo = FALSE, fig.width = 16, fig.height = 12}
library(DiagrammeR)

flowchart <- grViz("
digraph flowchart {
  graph [rankdir = LR]
  node [shape=box, style=filled, fillcolor=\"#e6f2ff\", fontname=\"Arial\"]
  edge [fontname=\"Arial\"]

  forestsearch [label=\"forestsearch (main entry)\", fillcolor=\"#b3d1ff\"]
  get_FSdata [label=\"get_FSdata\"]
  grf_subg [label=\"grf.subg.harm.survival\"]
  subgroup_search [label=\"subgroup.search\"]
  subgroup_consistency [label=\"subgroup.consistency\"]
  get_dfpred [label=\"get_dfpred\"]
  SG_tab_estimates [label=\"SG_tab_estimates\"]
  forestsearch_bootstrap [label=\"forestsearch_bootstrap_dofuture\"]

  # Main flow
  forestsearch -> get_FSdata
  forestsearch -> grf_subg
  forestsearch -> subgroup_search
  forestsearch -> subgroup_consistency
  forestsearch -> get_dfpred
  forestsearch -> SG_tab_estimates
  forestsearch -> forestsearch_bootstrap

  # get_FSdata helpers
  get_FSdata -> lasso_selection
  get_FSdata -> get_conf_force
  get_FSdata -> filter_by_lassokeep
  get_FSdata -> is_continuous
  get_FSdata -> cut_var
  get_FSdata -> process_conf_force_expr
  get_FSdata -> dummy
  get_FSdata -> dummy2

  # grf_subg helpers
  grf_subg -> policy_tree
  grf_subg -> causal_survival_forest
  grf_subg -> double_robust_scores
  grf_subg -> aggregate

  # subgroup_search helpers
  subgroup_search -> get_combinations_info
  subgroup_search -> get_subgroup_membership
  subgroup_search -> get_covs_in
  subgroup_search -> extract_idx_flagredundancy

  # subgroup_consistency helpers
  subgroup_consistency -> sort_subgroups
  subgroup_consistency -> extract_subgroup
  subgroup_consistency -> sg_consistency_out
  subgroup_consistency -> remove_redundant_subgroups
  subgroup_consistency -> get_split_hr
  subgroup_consistency -> setup_parallel_SGcons

  # forestsearch_bootstrap helpers
  forestsearch_bootstrap -> bootstrap_results
  forestsearch_bootstrap -> bootstrap_ystar
  forestsearch_bootstrap -> get_dfRes
  forestsearch_bootstrap -> get_Cox_sg
  forestsearch_bootstrap -> ci_est
  forestsearch_bootstrap -> get_targetEst
  forestsearch_bootstrap -> fit_cox_models
  forestsearch_bootstrap -> build_cox_formula
  forestsearch_bootstrap -> ensure_packages
  forestsearch_bootstrap -> setup_parallel_SGcons

  # SG_tab_estimates helpers
  SG_tab_estimates -> analyze_subgroup
  analyze_subgroup [label=\"analyze_subgroup\"]
  analyze_subgroup -> cox_summary
  analyze_subgroup -> km_summary
  analyze_subgroup -> rmst_calculation
  analyze_subgroup -> calculate_counts
  analyze_subgroup -> calculate_potential_hr
  SG_tab_estimates -> prepare_subgroup_data
  SG_tab_estimates -> format_results
  SG_tab_estimates -> format_CI
}
", width = 800, height = 800)
flowchart
```

